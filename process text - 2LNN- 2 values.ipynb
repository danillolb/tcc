{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no_z_PlmHWY9"
   },
   "source": [
    "## PROCESSANDO AS QUESTÕES\n",
    "#### Utilizando GloVe 100 Dim - Português\n",
    "#### Dataset: Questão sobre cientificidade da Psicologia - PUC GO - Prof. Weber Martins, PhD\n",
    "\n",
    "#### 2 labels classificando por notas agrupadas da seguinte forma:\n",
    "##### notas menores que 5, notas maiores que 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MF885-ehHWY_",
    "outputId": "0a40ab72-9e90-4299-fa54-d5f3f5338336"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\danil\\appdata\\local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "c:\\users\\danil\\appdata\\local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "\n",
    "\n",
    "from __future__ import print_function \n",
    "\n",
    "import gensim\n",
    "from gensim import utils\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "import ml_metrics as metrics\n",
    "\n",
    "##### edit\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    " \n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjCsp5FPHWZE"
   },
   "source": [
    "#### definir variáveis globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "egIjWRfTHWZF"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = ''\n",
    "GLOVE_DIR = os.path.join(BASE_DIR, 'glove_s100')\n",
    "FNAME = 'preprocessado_sem_stopwords.csv'\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 10000\n",
    "EMBEDDING_DIM = 100\n",
    "VALIDATION_SPLIT = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4lfnsNz6HWZH"
   },
   "source": [
    "#### Carregar o word embedding no gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PuH1ozKXHWZI"
   },
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format(os.path.join(GLOVE_DIR, 'glove_s100.txt'), binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ChIeqTfHWZK"
   },
   "source": [
    "#### indexando word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Q1hj25TKHWZL",
    "outputId": "e7d9e045-babb-43c9-de0a-b9511baeff7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n"
     ]
    }
   ],
   "source": [
    "print('Processing text dataset')\n",
    "\n",
    "df = pd.read_csv(FNAME, encoding = \"iso-8859-1\")\n",
    "texts = df['resposta'].values.tolist()\n",
    "labels = df['nota'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gu3ivuSaHWZO",
    "outputId": "d56d303c-8722-4256-a4c4-9fc883efa50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0_6': 169, '6_10': 73}\n"
     ]
    }
   ],
   "source": [
    "quantidade= {'0_5': 0, '6_10':0}\n",
    "for count, l in enumerate(labels, start = 0):\n",
    "    if l < 6:\n",
    "        labels[count] = 0\n",
    "        quantidade['0_5'] += 1\n",
    "    else:\n",
    "        labels[count] = 1\n",
    "        quantidade['6_10'] += 1\n",
    "\n",
    "labels\n",
    "print(quantidade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-K3wcifHWZR"
   },
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tJjzaD_pHWZS"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    doc = text_to_word_sequence(text)\n",
    "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "N3OUMAKiHWZU"
   },
   "outputs": [],
   "source": [
    "corpus = [preprocess(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIGrtolZHWZW"
   },
   "source": [
    "### Remove empty docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7YebYz72HWZX"
   },
   "outputs": [],
   "source": [
    "def filter_docs(corpus, texts, labels, condition_on_doc):\n",
    "    \"\"\"\n",
    "    Filter corpus, texts and labels given the function condition_on_doc which takes\n",
    "    a doc.\n",
    "    The document doc is kept if condition_on_doc(doc) is true.\n",
    "    \"\"\"\n",
    "    number_of_docs = len(corpus)\n",
    "\n",
    "    if texts is not None:\n",
    "        texts = [text for (text, doc) in zip(texts, corpus)\n",
    "                 if condition_on_doc(doc)]\n",
    "\n",
    "    labels = [i for (i, doc) in zip(labels, corpus) if condition_on_doc(doc)]\n",
    "    corpus = [doc for doc in corpus if condition_on_doc(doc)]\n",
    "\n",
    "    print(\"{} docs removed\".format(number_of_docs - len(corpus)))\n",
    "\n",
    "    return (corpus, texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3T4qGh_7HWZZ",
    "outputId": "536fb507-5e33-4a9b-9c6a-425ee58480d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "corpus, texts, labels = filter_docs(corpus, texts, labels, lambda doc: (len(doc) != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rHq088T8HWZd"
   },
   "source": [
    "### Remove words that are not in the model and documents that dont have a representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AfL-QgE_HWZd"
   },
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YpO4hMC8HWZf"
   },
   "outputs": [],
   "source": [
    "def has_vector_representation(word2vec_model, doc):\n",
    "    \"\"\"check if at least one word of the document is in the\n",
    "    word2vec dictionary\"\"\"\n",
    "    return not all(word not in word2vec_model.vocab for word in doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ts0ZkFEaHWZj",
    "outputId": "8e181bfd-ffd0-4756-f63c-b1fc28bbb202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 docs removed\n"
     ]
    }
   ],
   "source": [
    "corpus, texts, labels = filter_docs(corpus, texts, labels, lambda doc: has_vector_representation(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6YIsOwqMHWZm"
   },
   "outputs": [],
   "source": [
    "x =[]\n",
    "for doc in corpus: #look up each doc in model\n",
    "    x.append(document_vector(model, doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OETFPnoiHWZo"
   },
   "outputs": [],
   "source": [
    "X = np.array(x) #list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ou_uaZDSHWZr",
    "outputId": "a8c6c4dd-01ca-4e70-b8c3-0bd739bbd29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (242, 100)\n",
      "Shape of label tensor: (242, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(np.asarray(labels)) # to_categorical = Converts a class vector (integers) to binary class matrix. #asarray = converts the input to an array\n",
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qtVI2JQCHWZu"
   },
   "outputs": [],
   "source": [
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(X.shape[0]) #cria um vetor de inteiros do tamanho de data.shape[0]\n",
    "np.random.shuffle(indices) #mistura-se eles aleatoriamente\n",
    "data = X[indices] #atribui os dados e labels de indices randomizados\n",
    "labels = labels[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0]) #divide os dados em um fator inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XGdtYgjlHWZx"
   },
   "outputs": [],
   "source": [
    "x_train = data[:-num_validation_samples]\n",
    "y_train = labels[:-num_validation_samples]\n",
    "x_val = data[-num_validation_samples:]\n",
    "y_val = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ENmfrTdsHWZz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tmUeairrHWZ1",
    "outputId": "18bcdcca-fe79-45f0-e9ad-e2f6b3a0189b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Training model.')\n",
    "\n",
    "# train a 1D convnet with global maxpooling\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='float32')\n",
    "x = Dense(200, activation='relu')(sequence_input)\n",
    "#x = Dense(200, activation='relu')(x)\n",
    "preds = Dense(len(labels[1]), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sATH6Ea9HWZ4",
    "outputId": "aeae33d8-e6e8-4b34-ee1f-ac40a9556910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 170 samples, validate on 72 samples\n",
      "Epoch 1/100\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 0.6218 - acc: 0.6882 - val_loss: 0.6187 - val_acc: 0.7222\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 0s 65us/step - loss: 0.6315 - acc: 0.6941 - val_loss: 0.6099 - val_acc: 0.7222\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 0s 333us/step - loss: 0.6023 - acc: 0.6941 - val_loss: 0.6022 - val_acc: 0.7222\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 0s 83us/step - loss: 0.5937 - acc: 0.6941 - val_loss: 0.6044 - val_acc: 0.7222\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 0s 65us/step - loss: 0.5869 - acc: 0.6941 - val_loss: 0.6026 - val_acc: 0.7222\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 0s 77us/step - loss: 0.5814 - acc: 0.6941 - val_loss: 0.6045 - val_acc: 0.7222\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 0s 50us/step - loss: 0.5763 - acc: 0.6941 - val_loss: 0.6030 - val_acc: 0.7222\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.5716 - acc: 0.6941 - val_loss: 0.6055 - val_acc: 0.7222\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 0s 180us/step - loss: 0.5671 - acc: 0.6941 - val_loss: 0.6032 - val_acc: 0.7222\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 0s 106us/step - loss: 0.5631 - acc: 0.6941 - val_loss: 0.6086 - val_acc: 0.7222\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 0s 174us/step - loss: 0.5597 - acc: 0.7059 - val_loss: 0.6043 - val_acc: 0.7222\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 0s 103us/step - loss: 0.5580 - acc: 0.6941 - val_loss: 0.6157 - val_acc: 0.7361\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 0s 68us/step - loss: 0.5562 - acc: 0.7412 - val_loss: 0.6061 - val_acc: 0.7222\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 0s 88us/step - loss: 0.5538 - acc: 0.6941 - val_loss: 0.6140 - val_acc: 0.7361\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 0s 103us/step - loss: 0.5482 - acc: 0.7412 - val_loss: 0.6046 - val_acc: 0.7222\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 0s 100us/step - loss: 0.5436 - acc: 0.6941 - val_loss: 0.6106 - val_acc: 0.7361\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 0s 142us/step - loss: 0.5390 - acc: 0.7412 - val_loss: 0.6045 - val_acc: 0.7222\n",
      "Epoch 18/100\n",
      "170/170 [==============================] - 0s 139us/step - loss: 0.5353 - acc: 0.7000 - val_loss: 0.6095 - val_acc: 0.7361\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 0s 53us/step - loss: 0.5317 - acc: 0.7412 - val_loss: 0.6049 - val_acc: 0.7222\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 0s 142us/step - loss: 0.5287 - acc: 0.7118 - val_loss: 0.6108 - val_acc: 0.7361\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 0s 127us/step - loss: 0.5260 - acc: 0.7588 - val_loss: 0.6056 - val_acc: 0.7222\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 0s 77us/step - loss: 0.5233 - acc: 0.7176 - val_loss: 0.6136 - val_acc: 0.7500\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.5211 - acc: 0.7706 - val_loss: 0.6069 - val_acc: 0.7222\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 0s 133us/step - loss: 0.5193 - acc: 0.7118 - val_loss: 0.6159 - val_acc: 0.7222\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 0s 180us/step - loss: 0.5163 - acc: 0.7706 - val_loss: 0.6072 - val_acc: 0.7361\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 0s 153us/step - loss: 0.5133 - acc: 0.7235 - val_loss: 0.6145 - val_acc: 0.7361\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 0s 130us/step - loss: 0.5092 - acc: 0.7706 - val_loss: 0.6076 - val_acc: 0.7361\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 0s 74us/step - loss: 0.5058 - acc: 0.7235 - val_loss: 0.6131 - val_acc: 0.7500\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 0s 133us/step - loss: 0.5023 - acc: 0.7706 - val_loss: 0.6079 - val_acc: 0.7361\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 0s 103us/step - loss: 0.4992 - acc: 0.7353 - val_loss: 0.6140 - val_acc: 0.7083\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 0s 245us/step - loss: 0.4965 - acc: 0.7765 - val_loss: 0.6087 - val_acc: 0.7361\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.4941 - acc: 0.7353 - val_loss: 0.6162 - val_acc: 0.7083\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 0s 86us/step - loss: 0.4919 - acc: 0.7765 - val_loss: 0.6106 - val_acc: 0.7361\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 0s 127us/step - loss: 0.4901 - acc: 0.7353 - val_loss: 0.6187 - val_acc: 0.6944\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 0s 88us/step - loss: 0.4877 - acc: 0.7824 - val_loss: 0.6121 - val_acc: 0.7361\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.4851 - acc: 0.7529 - val_loss: 0.6186 - val_acc: 0.6944\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 0s 106us/step - loss: 0.4814 - acc: 0.7824 - val_loss: 0.6122 - val_acc: 0.7361\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.4780 - acc: 0.7588 - val_loss: 0.6178 - val_acc: 0.6944\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 0s 80us/step - loss: 0.4743 - acc: 0.7824 - val_loss: 0.6132 - val_acc: 0.7361\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 0s 56us/step - loss: 0.4712 - acc: 0.7588 - val_loss: 0.6179 - val_acc: 0.7083\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 0s 38us/step - loss: 0.4679 - acc: 0.7882 - val_loss: 0.6141 - val_acc: 0.7361\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 0s 74us/step - loss: 0.4657 - acc: 0.7647 - val_loss: 0.6207 - val_acc: 0.6806\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 0s 88us/step - loss: 0.4637 - acc: 0.8000 - val_loss: 0.6158 - val_acc: 0.7361\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 0s 162us/step - loss: 0.4623 - acc: 0.7588 - val_loss: 0.6226 - val_acc: 0.6806\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 0s 100us/step - loss: 0.4601 - acc: 0.8176 - val_loss: 0.6170 - val_acc: 0.7361\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 0s 100us/step - loss: 0.4575 - acc: 0.7647 - val_loss: 0.6222 - val_acc: 0.6806\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 0s 106us/step - loss: 0.4538 - acc: 0.8176 - val_loss: 0.6167 - val_acc: 0.7361\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 0s 68us/step - loss: 0.4510 - acc: 0.7765 - val_loss: 0.6218 - val_acc: 0.6944\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 0s 118us/step - loss: 0.4476 - acc: 0.8118 - val_loss: 0.6173 - val_acc: 0.7361\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 0s 144us/step - loss: 0.4448 - acc: 0.7765 - val_loss: 0.6222 - val_acc: 0.6944\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 0s 147us/step - loss: 0.4421 - acc: 0.8235 - val_loss: 0.6185 - val_acc: 0.7361\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 0s 189us/step - loss: 0.4398 - acc: 0.7765 - val_loss: 0.6239 - val_acc: 0.6944\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.4378 - acc: 0.8235 - val_loss: 0.6208 - val_acc: 0.7361\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.4362 - acc: 0.7824 - val_loss: 0.6269 - val_acc: 0.6667\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.4345 - acc: 0.8294 - val_loss: 0.6229 - val_acc: 0.7361\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 0s 100us/step - loss: 0.4327 - acc: 0.7824 - val_loss: 0.6282 - val_acc: 0.6667\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 0s 68us/step - loss: 0.4298 - acc: 0.8294 - val_loss: 0.6237 - val_acc: 0.7361\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.4270 - acc: 0.7941 - val_loss: 0.6276 - val_acc: 0.6806\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.4236 - acc: 0.8294 - val_loss: 0.6241 - val_acc: 0.7361\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 0s 83us/step - loss: 0.4209 - acc: 0.7882 - val_loss: 0.6281 - val_acc: 0.6806\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 0s 80us/step - loss: 0.4181 - acc: 0.8353 - val_loss: 0.6255 - val_acc: 0.7222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "170/170 [==============================] - 0s 298us/step - loss: 0.4157 - acc: 0.7941 - val_loss: 0.6295 - val_acc: 0.6806\n",
      "Epoch 63/100\n",
      "170/170 [==============================] - 0s 88us/step - loss: 0.4136 - acc: 0.8353 - val_loss: 0.6275 - val_acc: 0.7222\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 0s 168us/step - loss: 0.4117 - acc: 0.7941 - val_loss: 0.6320 - val_acc: 0.6944\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 0s 180us/step - loss: 0.4098 - acc: 0.8353 - val_loss: 0.6299 - val_acc: 0.7361\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 0s 115us/step - loss: 0.4082 - acc: 0.7941 - val_loss: 0.6341 - val_acc: 0.6806\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 0s 94us/step - loss: 0.4063 - acc: 0.8471 - val_loss: 0.6323 - val_acc: 0.7361\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 0s 103us/step - loss: 0.4043 - acc: 0.8000 - val_loss: 0.6349 - val_acc: 0.6806\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 0s 38us/step - loss: 0.4014 - acc: 0.8471 - val_loss: 0.6328 - val_acc: 0.7222\n",
      "Epoch 70/100\n",
      "170/170 [==============================] - 0s 94us/step - loss: 0.3986 - acc: 0.8059 - val_loss: 0.6344 - val_acc: 0.6944\n",
      "Epoch 71/100\n",
      "170/170 [==============================] - 0s 86us/step - loss: 0.3954 - acc: 0.8471 - val_loss: 0.6332 - val_acc: 0.7083\n",
      "Epoch 72/100\n",
      "170/170 [==============================] - 0s 100us/step - loss: 0.3928 - acc: 0.8059 - val_loss: 0.6354 - val_acc: 0.6944\n",
      "Epoch 73/100\n",
      "170/170 [==============================] - 0s 97us/step - loss: 0.3904 - acc: 0.8471 - val_loss: 0.6350 - val_acc: 0.7083\n",
      "Epoch 74/100\n",
      "170/170 [==============================] - 0s 86us/step - loss: 0.3885 - acc: 0.8118 - val_loss: 0.6377 - val_acc: 0.6806\n",
      "Epoch 75/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.3864 - acc: 0.8529 - val_loss: 0.6378 - val_acc: 0.7083\n",
      "Epoch 76/100\n",
      "170/170 [==============================] - 0s 44us/step - loss: 0.3851 - acc: 0.8176 - val_loss: 0.6408 - val_acc: 0.6528\n",
      "Epoch 77/100\n",
      "170/170 [==============================] - 0s 100us/step - loss: 0.3836 - acc: 0.8588 - val_loss: 0.6413 - val_acc: 0.7222\n",
      "Epoch 78/100\n",
      "170/170 [==============================] - 0s 83us/step - loss: 0.3827 - acc: 0.8118 - val_loss: 0.6431 - val_acc: 0.6667\n",
      "Epoch 79/100\n",
      "170/170 [==============================] - 0s 159us/step - loss: 0.3802 - acc: 0.8706 - val_loss: 0.6428 - val_acc: 0.7083\n",
      "Epoch 80/100\n",
      "170/170 [==============================] - 0s 38us/step - loss: 0.3781 - acc: 0.8294 - val_loss: 0.6429 - val_acc: 0.6528\n",
      "Epoch 81/100\n",
      "170/170 [==============================] - 0s 74us/step - loss: 0.3747 - acc: 0.8706 - val_loss: 0.6432 - val_acc: 0.6944\n",
      "Epoch 82/100\n",
      "170/170 [==============================] - 0s 53us/step - loss: 0.3720 - acc: 0.8529 - val_loss: 0.6433 - val_acc: 0.6806\n",
      "Epoch 83/100\n",
      "170/170 [==============================] - 0s 71us/step - loss: 0.3688 - acc: 0.8647 - val_loss: 0.6436 - val_acc: 0.6944\n",
      "Epoch 84/100\n",
      "170/170 [==============================] - 0s 62us/step - loss: 0.3664 - acc: 0.8471 - val_loss: 0.6445 - val_acc: 0.6806\n",
      "Epoch 85/100\n",
      "170/170 [==============================] - 0s 97us/step - loss: 0.3641 - acc: 0.8706 - val_loss: 0.6465 - val_acc: 0.6944\n",
      "Epoch 86/100\n",
      "170/170 [==============================] - 0s 109us/step - loss: 0.3626 - acc: 0.8529 - val_loss: 0.6480 - val_acc: 0.6667\n",
      "Epoch 87/100\n",
      "170/170 [==============================] - 0s 83us/step - loss: 0.3615 - acc: 0.8765 - val_loss: 0.6515 - val_acc: 0.6944\n",
      "Epoch 88/100\n",
      "170/170 [==============================] - 0s 127us/step - loss: 0.3613 - acc: 0.8529 - val_loss: 0.6514 - val_acc: 0.6667\n",
      "Epoch 89/100\n",
      "170/170 [==============================] - 0s 53us/step - loss: 0.3597 - acc: 0.8824 - val_loss: 0.6546 - val_acc: 0.6944\n",
      "Epoch 90/100\n",
      "170/170 [==============================] - 0s 50us/step - loss: 0.3584 - acc: 0.8471 - val_loss: 0.6534 - val_acc: 0.6667\n",
      "Epoch 91/100\n",
      "170/170 [==============================] - 0s 59us/step - loss: 0.3551 - acc: 0.8824 - val_loss: 0.6552 - val_acc: 0.6944\n",
      "Epoch 92/100\n",
      "170/170 [==============================] - 0s 86us/step - loss: 0.3524 - acc: 0.8529 - val_loss: 0.6527 - val_acc: 0.6667\n",
      "Epoch 93/100\n",
      "170/170 [==============================] - 0s 100us/step - loss: 0.3489 - acc: 0.8882 - val_loss: 0.6555 - val_acc: 0.6944\n",
      "Epoch 94/100\n",
      "170/170 [==============================] - 0s 38us/step - loss: 0.3466 - acc: 0.8529 - val_loss: 0.6547 - val_acc: 0.6944\n",
      "Epoch 95/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.3442 - acc: 0.8882 - val_loss: 0.6577 - val_acc: 0.6944\n",
      "Epoch 96/100\n",
      "170/170 [==============================] - 0s 103us/step - loss: 0.3425 - acc: 0.8588 - val_loss: 0.6571 - val_acc: 0.6667\n",
      "Epoch 97/100\n",
      "170/170 [==============================] - 0s 106us/step - loss: 0.3408 - acc: 0.8882 - val_loss: 0.6623 - val_acc: 0.6944\n",
      "Epoch 98/100\n",
      "170/170 [==============================] - 0s 97us/step - loss: 0.3401 - acc: 0.8529 - val_loss: 0.6611 - val_acc: 0.6667\n",
      "Epoch 99/100\n",
      "170/170 [==============================] - 0s 91us/step - loss: 0.3389 - acc: 0.9059 - val_loss: 0.6669 - val_acc: 0.6944\n",
      "Epoch 100/100\n",
      "170/170 [==============================] - 0s 103us/step - loss: 0.3382 - acc: 0.8529 - val_loss: 0.6639 - val_acc: 0.6528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2512948d128>"
      ]
     },
     "execution_count": 181,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=500,\n",
    "          epochs=100,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m4voEYdWHWZ6"
   },
   "source": [
    "# testando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "K5P3k-qUHWZ7"
   },
   "outputs": [],
   "source": [
    "predicted = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4JLMdPGLHWZ9"
   },
   "source": [
    "#### visualizando as notas esperadas e previstas pelo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "w-wve1gjHWZ9"
   },
   "outputs": [],
   "source": [
    "aux = np.array(predicted)\n",
    "np_predicted = np.zeros_like(aux)\n",
    "np_predicted[np.arange(len(aux)), aux.argmax(1)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pFqWlE_ZHWaA",
    "outputId": "94856915-b653-41ae-be1b-ca494d2797c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected predicted\n",
      "[0. 1.]   [1. 0.]\n",
      "[0. 1.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[0. 1.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[0. 1.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[1. 0.]   [1. 0.]\n",
      "[1. 0.]   [0. 1.]\n",
      "[0. 1.]   [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"expected predicted\")\n",
    "for count, l in enumerate(predicted, start = 0):\n",
    "    print(str(y_val[count]),\" \", np_predicted[count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GInGD75KHWaC"
   },
   "source": [
    "### QUADRATIC WEIGHTED KAPPA METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aecgz0Q9HWaD",
    "outputId": "45db5d21-1129-422b-a8e4-21bb8bb33149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0]\n",
      "[1 1 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.030172413793103536"
      ]
     },
     "execution_count": 185,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "predicted = np.argmax(np_predicted,axis = 1)\n",
    "expected = np.argmax(y_val, axis = 1)\n",
    "print(predicted)\n",
    "print(expected)\n",
    "\n",
    "qwk = metrics.quadratic_weighted_kappa(predicted, expected) \n",
    "\n",
    "qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "784ebuE6HWaG"
   },
   "source": [
    "# Registro de performance\n",
    "\n",
    "#### run 1, qwk: 0.16000000000000003, val_acc = 0.7083  , epochs = 30, vsplit = 0.1\n",
    "#### run 2, qwk: 0.00917431192660545, val_acc = 0.6250  , epochs = 30, vsplit = 0.2\n",
    "#### run 3, qwk: 0.04166666666666674, val_acc = 0.6806  , epochs = 30, vsplit = 0.3\n",
    "#### <font color = \"red\"> run 4, qwk: 0.2660944206008583, val_acc = 0.7361, epochs = 30, vsplit = 0.3 </font>\n",
    "#### run 5, qwk: 0.10891089108910901, val_acc = 0.6528, epochs = 50, vsplit = 0.3\n",
    "#### run 6, qwk: 0.030172413793103536, val_acc = 0.6528, epochs = 100, vsplit = 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u4zM8eneHWaG"
   },
   "source": [
    "## Sobre o dataset :\n",
    "\n",
    "#### tamanho de cada resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PooCf-qeHWaH"
   },
   "outputs": [],
   "source": [
    "tamanho = []\n",
    "for t in texts:\n",
    "    tamanho.append(len(t.split()))\n",
    "    if(len(t.split()) == 1):\n",
    "        print(t)\n",
    "print(tamanho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1iZopERPHWaJ"
   },
   "source": [
    "#### tamanho mínimo , tamanho máximo, tamanho médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "27TdYt0mHWaK"
   },
   "outputs": [],
   "source": [
    "min(tamanho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "w_2PXvOnHWaN"
   },
   "outputs": [],
   "source": [
    "max(tamanho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Bk5udchdHWaQ"
   },
   "outputs": [],
   "source": [
    "print(int(sum(tamanho)/len(tamanho)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Gy6-mRxwHWaS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "process text - 2LNN- 2 values.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
